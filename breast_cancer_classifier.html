<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>dHrMN4Kqf4LrmaB23kV6eWnhqwSVzLoAzMTUfiP5</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>
<div id="0cba4341" class="cell markdown">
<h1 id="breast-cancer-classification-with-machine-learning">Breast
Cancer Classification with Machine Learning</h1>
<p>This project builds an end-to-end machine learning pipeline to
classify breast cancer diagnoses as <strong>benign or malignant</strong>
using the <strong>Wisconsin Breast Cancer Dataset</strong>.</p>
<p>The focus is not only on predictive performance but also on
<strong>model evaluation under medical constraints</strong>, where false
negatives (missed cancers) are significantly more costly than false
positives.</p>
<!-- Key objectives:
- Build a robust preprocessing + modeling pipeline
- Compare multiple classification algorithms
- Optimize models using cross-validation and Bayesian optimization
- Evaluate performance using medically relevant metrics (ROC-AUC, recall)
- Analyze decision thresholds and probability calibration -->
</div>
<div id="ea00a8d8-8e4a-4c1b-b20c-49c52d4a05a3" class="cell code">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pandas scikit<span class="op">-</span>learn optuna matplotlib seaborn <span class="op">-</span>q</span></code></pre></div>
</div>
<div id="da9a5606-25f8-44f6-bafd-be70f90661a8" class="cell code"
data-execution_count="231">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Handle imports</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, StratifiedKFold</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, GradientBoostingClassifier</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score, confusion_matrix, classification_report, ConfusionMatrixDisplay</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> optuna</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> optuna.samplers <span class="im">import</span> TPESampler</span></code></pre></div>
</div>
<div id="9edfd9b7-ca69-4cb8-8ece-829432fc8667" class="cell code"
data-execution_count="232">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>RANDOM_STATE <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>TEST_SIZE <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>CV_FOLDS <span class="op">=</span> <span class="dv">5</span></span></code></pre></div>
</div>
<div id="43182ad2" class="cell markdown">
<h3 id="dataset-description">Dataset Description</h3>
</div>
<div id="b9d7fc58" class="cell code">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Breast Cancer data</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> pd.DataFrame(data.data, columns<span class="op">=</span>data.feature_names)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> pd.Series(data.target, name<span class="op">=</span><span class="st">&quot;target&quot;</span>)</span></code></pre></div>
</div>
<div id="766ba922" class="cell markdown">
<p>The dataset contains <strong>569 samples</strong> with <strong>30
numeric features</strong>, extracted from digitized images of breast
tissue. The target variable is <strong>binary</strong>:</p>
<ul>
<li>0 → Malignant</li>
<li>1 → Benign</li>
</ul>
<p>Class distribution is moderately <strong>imbalanced (~63% benign /
37% malignant)</strong>, motivating the use of <strong>stratified
cross-validation</strong> and ROC-AUC–based evaluation.</p>
</div>
<div id="fc084b56-32bd-4150-a54b-8a3e8260d394" class="cell code"
data-execution_count="234">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Dataset shape:&quot;</span>, X.shape)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Class distribution:</span><span class="ch">\n</span><span class="st">&quot;</span>, y.value_counts(normalize<span class="op">=</span><span class="va">True</span>))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Dataset shape: (569, 30)
Class distribution:
 target
1    0.627417
0    0.372583
Name: proportion, dtype: float64
</code></pre>
</div>
</div>
<div id="94c87200" class="cell markdown">
<p>The dataset contains 30 features extracted from tumor cell nuclei.
For each property (e.g., radius, texture, perimeter), three statistics
are recorded:</p>
<ul>
<li><strong>mean</strong>: average value across all cells</li>
<li><strong>error</strong>: standard error, measuring variability</li>
<li><strong>worst</strong>: largest observed value, often most
indicative of malignancy</li>
</ul>
</div>
<div id="5acd12e4" class="cell code" data-execution_count="235">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization of radius feature</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [<span class="st">&#39;mean radius&#39;</span>, <span class="st">&#39;radius error&#39;</span>, <span class="st">&#39;worst radius&#39;</span>]</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">5</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>sns.boxplot(data<span class="op">=</span>X[features])</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Comparison of Mean, Error, and Worst Radius&quot;</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Value&quot;</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="c0e2b1835c25ef2979d038ee2a489fe8a83d2bda.png" /></p>
</div>
</div>
<div id="2b180b73" class="cell markdown">
<h3 id="data-preprocessing">Data Preprocessing</h3>
</div>
<div id="a9bc9345" class="cell markdown">
<p>A <strong>stratified train/test</strong> split ensures class
proportions remain consistent. Model selection and tuning are performed
<strong>only on the training set</strong> using stratified k-fold
cross-validation to prevent data leakage.</p>
</div>
<div id="ef331c46-9640-47ab-962f-936b67ea3eff" class="cell code"
data-execution_count="236">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data into training and testing sets with stratification</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    X, y,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    test_size<span class="op">=</span>TEST_SIZE,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    stratify<span class="op">=</span>y,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span>RANDOM_STATE</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>cv <span class="op">=</span> StratifiedKFold(n_splits<span class="op">=</span>CV_FOLDS, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span>RANDOM_STATE)</span></code></pre></div>
</div>
<div id="5aca7d7f" class="cell markdown">
<p>All preprocessing steps are encapsulated in a <strong>scikit-learn
pipeline</strong> to ensure:</p>
<ul>
<li>No data leakage</li>
<li>Reproducibility</li>
<li>Consistent preprocessing across cross-validation folds</li>
</ul>
</div>
<div id="ba2c8718-bbe4-40ec-b4e4-0325894177b9" class="cell code"
data-execution_count="237">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply data transformations using sklearn PIPELINE</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>numeric_transformer <span class="op">=</span> Pipeline([</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>(<span class="st">&#39;imputer&#39;</span>, SimpleImputer(strategy<span class="op">=</span><span class="st">&#39;median&#39;</span>)),</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>(<span class="st">&#39;scaler&#39;</span>, StandardScaler())</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> ColumnTransformer([</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>(<span class="st">&#39;num&#39;</span>, numeric_transformer, X.columns)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>])</span></code></pre></div>
</div>
<div id="204089e9" class="cell markdown">
<h3 id="model-training-and-evaluation">Model Training and
Evaluation</h3>
<p>We evaluate several models using stratified cross-validation:</p>
</div>
<div id="838d5b7e-3886-453f-ba55-9ed3f7a2e9d5" class="cell code"
data-execution_count="238">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate multiple models using cross-validation</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> {</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Logistic Regression&quot;</span>: LogisticRegression(max_iter<span class="op">=</span><span class="dv">2000</span>),</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;SVC&quot;</span>: SVC(probability<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Random Forest&quot;</span>: RandomForestClassifier(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Gradient Boosting&quot;</span>: GradientBoostingClassifier(random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, clf <span class="kw">in</span> models.items():</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    pipe <span class="op">=</span> Pipeline([</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&quot;prep&quot;</span>, preprocessor),</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&quot;clf&quot;</span>, clf)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    roc_auc <span class="op">=</span> cross_val_score(pipe, X_train, y_train, cv<span class="op">=</span>cv, scoring<span class="op">=</span><span class="st">&quot;roc_auc&quot;</span>).mean()</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    recall <span class="op">=</span> cross_val_score(pipe, X_train, y_train, cv<span class="op">=</span>cv, scoring<span class="op">=</span><span class="st">&quot;recall&quot;</span>).mean()</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    results.append([name, roc_auc, recall])</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(results, columns<span class="op">=</span>[<span class="st">&quot;Model&quot;</span>, <span class="st">&quot;ROC-AUC&quot;</span>, <span class="st">&quot;Recall&quot;</span>]).sort_values(<span class="st">&quot;ROC-AUC&quot;</span>, ascending<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="238">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>ROC-AUC</th>
      <th>Recall</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Logistic Regression</td>
      <td>0.995872</td>
      <td>0.985965</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SVC</td>
      <td>0.995562</td>
      <td>0.978947</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Gradient Boosting</td>
      <td>0.991847</td>
      <td>0.961404</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Random Forest</td>
      <td>0.989577</td>
      <td>0.964912</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div id="f3eca6d4" class="cell markdown">
<p>Logistic Regression and SVC achieved the strongest cross-validated
ROC-AUC.</p>
<p>We evaluate ROC curve to avoid missing malignant cancers and
unnecessary biopsies.</p>
<p><strong>Logistic Regression</strong> was selected for further
optimization due to:</p>
<ul>
<li>Comparable performance</li>
<li>Better interpretability</li>
<li>Well-calibrated probability outputs</li>
</ul>
<!-- 1. Comparable performance

“Logistic Regression performed just as well as the more complex models in ROC-AUC and recall, so there was no accuracy advantage in choosing a more complicated model.”

2. Better interpretability →

“Logistic Regression is much easier to understand and explain, because its coefficients show how each feature affects the prediction—an important requirement in medical applications.”

3. Well-calibrated probability outputs →

“Logistic Regression produces reliable probability scores, meaning its predicted risks closely match real-world outcomes without needing additional calibration steps.” -->
</div>
<div id="ae016c11" class="cell markdown">
<h3 id="hyperparameter-optimization">Hyperparameter Optimization</h3>
<p><strong>Bayesian optimization</strong> via <strong>Optuna</strong>
was used to tune the C parameter efficiently:</p>
</div>
<div id="45534d84-c6e2-4a0f-95d1-f8f94a871827" class="cell code"
data-execution_count="239">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to tell Optuna what to optimize</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective(trial):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> trial.suggest_float(<span class="st">&quot;C&quot;</span>, <span class="fl">0.001</span>, <span class="fl">10.0</span>, log<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LogisticRegression(C<span class="op">=</span>C, max_iter<span class="op">=</span><span class="dv">3000</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    pipe <span class="op">=</span> Pipeline([</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&quot;prep&quot;</span>, preprocessor),</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&quot;clf&quot;</span>, model)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cross_val_score(pipe, X_train, y_train, cv<span class="op">=</span>cv, scoring<span class="op">=</span><span class="st">&quot;roc_auc&quot;</span>).mean()</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>study <span class="op">=</span> optuna.create_study(direction<span class="op">=</span><span class="st">&quot;maximize&quot;</span>, sampler<span class="op">=</span>TPESampler(seed<span class="op">=</span>RANDOM_STATE), study_name<span class="op">=</span><span class="st">&quot;Logistic_Regression_Optimization&quot;</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>study.optimize(objective, n_trials<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>study.best_params</span></code></pre></div>
<div class="output stream stderr">
<pre><code>[I 2026-01-07 16:05:33,933] A new study created in memory with name: Logistic_Regression_Optimization
[I 2026-01-07 16:05:34,083] Trial 0 finished with value: 0.9941176470588236 and parameters: {&#39;C&#39;: 0.03148911647956861}. Best is trial 0 with value: 0.9941176470588236.
[I 2026-01-07 16:05:34,203] Trial 1 finished with value: 0.9932920536635705 and parameters: {&#39;C&#39;: 6.351221010640703}. Best is trial 0 with value: 0.9941176470588236.
[I 2026-01-07 16:05:34,314] Trial 2 finished with value: 0.9957688338493291 and parameters: {&#39;C&#39;: 0.8471801418819978}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:34,451] Trial 3 finished with value: 0.9953560371517026 and parameters: {&#39;C&#39;: 0.24810409748678125}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:34,584] Trial 4 finished with value: 0.9900928792569659 and parameters: {&#39;C&#39;: 0.004207988669606638}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:34,680] Trial 5 finished with value: 0.9900928792569659 and parameters: {&#39;C&#39;: 0.004207053950287938}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:34,770] Trial 6 finished with value: 0.9878224974200206 and parameters: {&#39;C&#39;: 0.0017073967431528124}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:34,884] Trial 7 finished with value: 0.9944272445820432 and parameters: {&#39;C&#39;: 2.9154431891537547}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:34,987] Trial 8 finished with value: 0.9953560371517026 and parameters: {&#39;C&#39;: 0.2537815508265665}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:35,087] Trial 9 finished with value: 0.9957688338493291 and parameters: {&#39;C&#39;: 0.679657809075816}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:35,202] Trial 10 finished with value: 0.993704850361197 and parameters: {&#39;C&#39;: 0.019188765741731954}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:35,482] Trial 11 finished with value: 0.9957688338493291 and parameters: {&#39;C&#39;: 1.1281508722889861}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:35,820] Trial 12 finished with value: 0.9957688338493291 and parameters: {&#39;C&#39;: 0.6087951913361184}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:36,255] Trial 13 finished with value: 0.9950464396284829 and parameters: {&#39;C&#39;: 0.07870338212964717}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:36,471] Trial 14 finished with value: 0.995252837977296 and parameters: {&#39;C&#39;: 1.717777390062754}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:36,738] Trial 15 finished with value: 0.9956656346749225 and parameters: {&#39;C&#39;: 0.4740514114700396}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:36,915] Trial 16 finished with value: 0.9929824561403509 and parameters: {&#39;C&#39;: 7.094400611517827}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:37,014] Trial 17 finished with value: 0.9950464396284829 and parameters: {&#39;C&#39;: 0.07821711764360048}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:37,121] Trial 18 finished with value: 0.9950464396284829 and parameters: {&#39;C&#39;: 2.1881094675744945}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:37,214] Trial 19 finished with value: 0.995252837977296 and parameters: {&#39;C&#39;: 0.16101280030617346}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:37,322] Trial 20 finished with value: 0.9957688338493291 and parameters: {&#39;C&#39;: 0.7473456802129258}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:37,470] Trial 21 finished with value: 0.9956656346749225 and parameters: {&#39;C&#39;: 1.2389260705332845}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:37,709] Trial 22 finished with value: 0.9943240454076367 and parameters: {&#39;C&#39;: 3.8612121431699657}. Best is trial 2 with value: 0.9957688338493291.
[I 2026-01-07 16:05:37,849] Trial 23 finished with value: 0.9958720330237357 and parameters: {&#39;C&#39;: 0.9914156315561331}. Best is trial 23 with value: 0.9958720330237357.
[I 2026-01-07 16:05:37,981] Trial 24 finished with value: 0.9955624355005159 and parameters: {&#39;C&#39;: 0.47059166634892613}. Best is trial 23 with value: 0.9958720330237357.
[I 2026-01-07 16:05:38,093] Trial 25 finished with value: 0.9953560371517026 and parameters: {&#39;C&#39;: 0.3007016232607128}. Best is trial 23 with value: 0.9958720330237357.
[I 2026-01-07 16:05:38,563] Trial 26 finished with value: 0.995252837977296 and parameters: {&#39;C&#39;: 0.13176068071625943}. Best is trial 23 with value: 0.9958720330237357.
[I 2026-01-07 16:05:38,699] Trial 27 finished with value: 0.9922600619195047 and parameters: {&#39;C&#39;: 9.642078659880074}. Best is trial 23 with value: 0.9958720330237357.
[I 2026-01-07 16:05:38,804] Trial 28 finished with value: 0.9944272445820432 and parameters: {&#39;C&#39;: 0.040234933894050716}. Best is trial 23 with value: 0.9958720330237357.
[I 2026-01-07 16:05:39,065] Trial 29 finished with value: 0.9957688338493291 and parameters: {&#39;C&#39;: 1.0366565726204244}. Best is trial 23 with value: 0.9958720330237357.
</code></pre>
</div>
<div class="output execute_result" data-execution_count="239">
<pre><code>{&#39;C&#39;: 0.9914156315561331}</code></pre>
</div>
</div>
<div id="543ae02b" class="cell code" data-execution_count="240">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting the model with the best C parameter from the study</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>best_model <span class="op">=</span> Pipeline([</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;prep&quot;</span>, preprocessor),</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;clf&quot;</span>, LogisticRegression(<span class="op">**</span>study.best_params, max_iter<span class="op">=</span><span class="dv">3000</span>))</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>best_model.fit(X_train, y_train)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> best_model.predict(X_test)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>y_prob <span class="op">=</span> best_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span></code></pre></div>
</div>
<div id="f1d0ed9a" class="cell code" data-execution_count="241">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Classification Report:&quot;</span>, classification_report(y_test, y_pred))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;ROC-AUC:&quot;</span>, roc_auc_score(y_test, y_prob))</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Confusion Matrix:&quot;</span>, ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Classification Report:               precision    recall  f1-score   support

           0       0.98      0.98      0.98        42
           1       0.99      0.99      0.99        72

    accuracy                           0.98       114
   macro avg       0.98      0.98      0.98       114
weighted avg       0.98      0.98      0.98       114

ROC-AUC: 0.9953703703703703
Confusion Matrix: &lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x000001FF0F94D550&gt;
</code></pre>
</div>
<div class="output display_data">
<p><img src="4fa45bfbaf2aefd09265456967638ce63ab36243.png" /></p>
</div>
</div>
<div id="138d6a1c" class="cell markdown">
<p>The linear model identifies the <strong>most influential
features</strong> for prediction, with the highest coefficients
attributed to <strong>worst texture, radius error, and worst concave
points</strong>. These features contributed most strongly to the model’s
output.</p>
</div>
<div id="4cbce815" class="cell code">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract coefficients and sort by absolute value</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>coef <span class="op">=</span> pd.Series(</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    best_model.named_steps[<span class="st">&quot;clf&quot;</span>].coef_[<span class="dv">0</span>],</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>X.columns</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>).sort_values(key<span class="op">=</span><span class="bu">abs</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Take top 10 features</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>top_features <span class="op">=</span> coef.head(<span class="dv">10</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">3</span>))</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">&#39;green&#39;</span> <span class="cf">if</span> c <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">&#39;red&#39;</span> <span class="cf">for</span> c <span class="kw">in</span> top_features]  <span class="co"># positive = green, negative = red</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>plt.barh(top_features.index[::<span class="op">-</span><span class="dv">1</span>], top_features[::<span class="op">-</span><span class="dv">1</span>], color<span class="op">=</span>colors)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Coefficient value&quot;</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Top 10 influential features according to logistic regression coefficients&quot;</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>plt.grid(axis<span class="op">=</span><span class="st">&#39;x&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="e3ff25437cf36980c02e985bc908277da7942c6f.png" /></p>
</div>
</div>
<div id="b67a610b" class="cell markdown">
<p><strong>Threshold analysis</strong> demonstrates how the same model
can be adapted to:</p>
<ul>
<li>High-sensitivity screening contexts</li>
<li>Balanced diagnostic confirmation</li>
</ul>
<p>We can adjust the decision threshold to prioritize high recall
(sensitivity) or specificity:</p>
</div>
<div id="515ddbd2" class="cell code" data-execution_count="243">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> threshold <span class="kw">in</span> [<span class="fl">0.35</span>, <span class="fl">0.5</span>, <span class="fl">0.65</span>]:</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> (y_prob <span class="op">&gt;=</span> threshold).astype(<span class="bu">int</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    tn, fp, fn, tp <span class="op">=</span> confusion_matrix(y_test, preds).ravel()</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Threshold </span><span class="sc">{</span>threshold<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Recall: </span><span class="sc">{</span>tp<span class="op">/</span>(tp<span class="op">+</span>fn)<span class="sc">:.3f}</span><span class="ss">, Specificity: </span><span class="sc">{</span>tn<span class="op">/</span>(tn<span class="op">+</span>fp)<span class="sc">:.3f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Threshold 0.35
Recall: 1.000, Specificity: 0.952

Threshold 0.5
Recall: 0.986, Specificity: 0.976

Threshold 0.65
Recall: 0.931, Specificity: 0.976
</code></pre>
</div>
</div>
<div id="2f8d3153" class="cell markdown">
<h2 id="conclusions">Conclusions</h2>
<ul>
<li>Built a <strong>production-style ML pipeline</strong> with robust
preprocessing and cross-validation.</li>
<li>Achieved ROC-AUC ≈ 0.99 with high sensitivity on held-out data</li>
<li>Demonstrated how medical risk considerations influence model
evaluation and threshold selection.</li>
</ul>
</div>
</body>
</html>
